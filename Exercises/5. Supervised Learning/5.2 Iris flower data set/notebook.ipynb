{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "racial-preserve",
   "metadata": {},
   "source": [
    "**b)** Read the data from the CSV file and check the data using the `head()`, `describe()`, and other\n",
    "Pandas commands. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = pd.read_csv(os.getcwd() + \"/iris-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-nigeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-billy",
   "metadata": {},
   "source": [
    "**c)** Read again the data marking the missing values with ‘NA’. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-improvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('iris-data.csv', na_values=['NA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-clarity",
   "metadata": {},
   "source": [
    "**d)** Import the MatPlotLib and Seaborn libraries and create a scatterplot matrix of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-export",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(df.dropna(), hue='class');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-pharmaceutical",
   "metadata": {},
   "source": [
    "**e)** After looking at the plot it seems that the field researchers make some errors inserting the\n",
    "data. It sounds like one of them forgot to add Iris- before their Iris-versicolor entries. The\n",
    "other extraneous class, Iris-setossa, was simply a typo that they forgot to fix. Use the\n",
    "DataFrame to fix these errors. Create a new scatterplot of the data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-designation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['class'] == 'versicolor', 'class'] = 'Iris-versicolor'\n",
    "df.loc[df['class'] == 'Iris-setossa', 'class'] = 'Iris-setosa'\n",
    "\n",
    "df['class'].unique()\n",
    "sns.pairplot(df.dropna(), hue='class');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-barrel",
   "metadata": {},
   "source": [
    "**f)** Looking at the scatter plot, since it is impossible to have any 'Iris-setosa' rows with a sepal\n",
    "width less than 2.5 cm, drop those values and create an histogram with the 'Iris-setosa' sepal\n",
    "width. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-iraqi",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[(df['class'] != 'Iris-setosa') | (df['sepal_width_cm'] >= 2.5)]\n",
    "df.loc[df['class'] == 'Iris-setosa', 'sepal_width_cm'].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-blake",
   "metadata": {},
   "source": [
    "**g)** The next data issue to address is the several near-zero sepal lengths for the Iris-versicolor\n",
    "rows. Those rows were gathered in meters instead of cm. Please correct that mistake and\n",
    "draw the corresponding histogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-compiler",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['class'] == 'Iris-versicolor') & (df['sepal_length_cm'] < 1.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-basket",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['class'] == 'Iris-versicolor') & (df['sepal_length_cm'] < 1.0), 'sepal_length_cm'] *= 100.0\n",
    "df.loc[df['class'] == 'Iris-versicolor', 'sepal_length_cm'].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-degree",
   "metadata": {},
   "source": [
    "**h)** One way to deal with missing data is mean imputation. Do that for the missing values of the\n",
    "petal widths for Iris-setosa and create a new scatter plot for the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-blogger",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_petal_width = df.loc[df['class'] == 'Iris-setosa', 'petal_width_cm'].mean()\n",
    "\n",
    "df.loc[(df['class'] == 'Iris-setosa') & (df['petal_width_cm'].isnull()), 'petal_width_cm'] = average_petal_width\n",
    "df.loc[(df['class'] == 'Iris-setosa') & (df['petal_width_cm'] == average_petal_width)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-tooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue='class');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-single",
   "metadata": {},
   "source": [
    "**i)** Save the new clean dataset to the disk with the name “iris-data-clean.csv”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-modern",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('iris-data-clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-zambia",
   "metadata": {},
   "source": [
    "**j)** Create some violin plots of the data to compare the measurement distributions of the\n",
    "classes. Violin plots contain the same information as box plots, but also scales the box\n",
    "according to the density of the data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-affect",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for column_index, column in enumerate(df.columns):\n",
    "    if column != 'class':\n",
    "        plt.subplot(2, 2, column_index + 1)\n",
    "        sns.violinplot(x='class', y=column, data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-convenience",
   "metadata": {},
   "source": [
    "**k)** Create two variables with the inputs and labels using the clean dataset created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-breeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['sepal_length_cm', 'sepal_width_cm', 'petal_length_cm', 'petal_width_cm']].values  # Inputs\n",
    "y = df['class'].values                                                                     # Labels\n",
    "\n",
    "x[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-secondary",
   "metadata": {},
   "source": [
    "**l)** Import the `train_test_split` and create randomly training and testing sets with 75% of the\n",
    "examples on the training set and 25% on the testing set: training_inputs, testing_inputs,\n",
    "training_classes, testing_classes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-karen",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-curve",
   "metadata": {},
   "source": [
    "**m)** Import the DecisionTreeClassifier and train the classifier on the training set showing the final\n",
    "score/accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-colony",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create the classifier\n",
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Train the classifier on the training set\n",
    "decision_tree_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Validate the classifier on the testing set using classification accuracy\n",
    "decision_tree_classifier.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-hollywood",
   "metadata": {},
   "source": [
    "**n)** Experiment 1000 times the classifier and plot a histogram of the obtained accuracies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-thong",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracies = []\n",
    "\n",
    "for repetition in range(1000):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "    \n",
    "    decision_tree_classifier = DecisionTreeClassifier()\n",
    "    decision_tree_classifier.fit(x_train, y_train)\n",
    "    classifier_accuracy = decision_tree_classifier.score(x_test, y_test)\n",
    "    model_accuracies.append(classifier_accuracy)\n",
    "    \n",
    "plt.hist(model_accuracies);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-rochester",
   "metadata": {},
   "source": [
    "**o)** Import StratifiedKFold and use stratified cross-validation with 10 splits and train again the\n",
    "data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-character",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def plot_cv(cv, features, labels):\n",
    "    masks = []\n",
    "    for train, test in cv.split(features, labels):\n",
    "        mask = np.zeros(len(labels), dtype=bool)\n",
    "        mask[test] = 1\n",
    "        masks.append(mask)\n",
    "    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(masks, interpolation='none', cmap='gray_r')\n",
    "    plt.ylabel('Fold')\n",
    "    plt.xlabel('Row #')\n",
    "\n",
    "plot_cv(StratifiedKFold(n_splits=10), x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-cisco",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# cross_val_score returns a list of the scores, which we can visualize\n",
    "# to get a reasonable estimate of our classifier's performance\n",
    "cv_scores = cross_val_score(decision_tree_classifier, x, y, cv=10)\n",
    "plt.hist(cv_scores)\n",
    "plt.title('Average score: {}'.format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-mining",
   "metadata": {},
   "source": [
    "**p)** Import GridSearchCV and perform a Grid Search over the Decision Tree parameters to find\n",
    "the best parameters, visualizing the grid with the accuracies for each parameters pairs\n",
    "(max_features 1-4 and max_depth 1-5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "parameter_grid = {'max_depth': [1, 2, 3, 4, 5], 'max_features': [1, 2, 3, 4]}\n",
    "\n",
    "cross_validation = StratifiedKFold(n_splits=10)\n",
    "\n",
    "grid_search = GridSearchCV(decision_tree_classifier, param_grid=parameter_grid, cv=cross_validation)\n",
    "\n",
    "grid_search.fit(x, y)\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-inspection",
   "metadata": {},
   "source": [
    "**q)** Visualize in a graphical manner the final decision tree achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_visualization = grid_search.cv_results_['mean_test_score']\n",
    "grid_visualization.shape = (5, 4)\n",
    "sns.heatmap(grid_visualization, cmap='Blues', annot=True)\n",
    "plt.xticks(np.arange(4) + 0.5, grid_search.param_grid['max_features'])\n",
    "plt.yticks(np.arange(5) + 0.5, grid_search.param_grid['max_depth'])\n",
    "plt.xlabel('max_features')\n",
    "plt.ylabel('max_depth');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "parameter_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [1, 2, 3, 4, 5],\n",
    "    'max_features': [1, 2, 3, 4]\n",
    "}\n",
    "\n",
    "cross_validation = StratifiedKFold(n_splits=10)\n",
    "\n",
    "grid_search = GridSearchCV(decision_tree_classifier, param_grid=parameter_grid, cv=cross_validation)\n",
    "grid_search.fit(x, y)\n",
    "\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-namibia",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_classifier = grid_search.best_estimator_\n",
    "decision_tree_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-radical",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.tree as tree\n",
    "\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "tree.plot_tree(decision_tree_classifier, feature_names=x, class_names=y, filled=True);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
